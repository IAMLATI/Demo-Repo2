{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGxrvQC00+pyRD1waEeAdR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IAMLATI/Demo-Repo2/blob/master/Untitled74.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV1iEehGtCSz",
        "outputId": "9c7b1f86-f5af-4369-9fb7-5f9f7444837e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "CtaKVPJy0J1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315cb1d5-eb0f-4a6e-b33e-ef208f03426f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=\"\"\"\n",
        "Hello Welcome, My Name is Olamide, and I am learning Naik's\n",
        "tutorials.\n",
        "I will watch the entire course! to become an expert.\n",
        "\n",
        "Thank you.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "P7EnXJmH0pKl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "VSbb_Ezs0G4f",
        "outputId": "f6aed04c-cd02-4a16-e056-36517e0287d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nHello Welcome, My Name is Olamide, and I am learning Naik's\\ntutorials.\\nI will watch the entire course! to become an expert.\\n\\nThank you.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents=sent_tokenize(corpus)"
      ],
      "metadata": {
        "id": "vIUZedfGJX3x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqQU8M2NMQ4N",
        "outputId": "68fc3715-ed9f-4f5a-de94-fd25d544fdfe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in documents:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHNEGRC-MMnN",
        "outputId": "0ac27431-40b6-4c9b-d42f-8479b0287038"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hello Welcome, My Name is Olamide, and I am learning Naik's\n",
            "tutorials.\n",
            "I will watch the entire course!\n",
            "to become an expert.\n",
            "Thank you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Word_documents=word_tokenize(corpus)"
      ],
      "metadata": {
        "id": "-w_qWZn6X2d1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in Word_documents:\n",
        "  print(word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbvUiBjpYEet",
        "outputId": "de9fce7b-82c3-450b-80e0-a1a9d62abc43"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "Welcome\n",
            ",\n",
            "My\n",
            "Name\n",
            "is\n",
            "Olamide\n",
            ",\n",
            "and\n",
            "I\n",
            "am\n",
            "learning\n",
            "Naik\n",
            "'s\n",
            "tutorials\n",
            ".\n",
            "I\n",
            "will\n",
            "watch\n",
            "the\n",
            "entire\n",
            "course\n",
            "!\n",
            "to\n",
            "become\n",
            "an\n",
            "expert\n",
            ".\n",
            "Thank\n",
            "you\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in documents:\n",
        "  print(word_tokenize(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FadlDERy6mp-",
        "outputId": "8bcdf3df-d300-48db-a53d-3e85bfa7dd3f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Welcome', ',', 'My', 'Name', 'is', 'Olamide', ',', 'and', 'I', 'am', 'learning', 'Naik', \"'s\", 'tutorials', '.']\n",
            "['I', 'will', 'watch', 'the', 'entire', 'course', '!']\n",
            "['to', 'become', 'an', 'expert', '.']\n",
            "['Thank', 'you', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize"
      ],
      "metadata": {
        "id": "VLX4p37GYpZ3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordpunct_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIxmCtJi7qw5",
        "outputId": "30876c1f-9009-4709-8730-8a882651cfec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'Welcome',\n",
              " ',',\n",
              " 'My',\n",
              " 'Name',\n",
              " 'is',\n",
              " 'Olamide',\n",
              " ',',\n",
              " 'and',\n",
              " 'I',\n",
              " 'am',\n",
              " 'learning',\n",
              " 'Naik',\n",
              " \"'\",\n",
              " 's',\n",
              " 'tutorials',\n",
              " '.',\n",
              " 'I',\n",
              " 'will',\n",
              " 'watch',\n",
              " 'the',\n",
              " 'entire',\n",
              " 'course',\n",
              " '!',\n",
              " 'to',\n",
              " 'become',\n",
              " 'an',\n",
              " 'expert',\n",
              " '.',\n",
              " 'Thank',\n",
              " 'you',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ],
      "metadata": {
        "id": "XcxwYmX9JbBB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=TreebankWordTokenizer()"
      ],
      "metadata": {
        "id": "hUibHxI-Jm5k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hjsLZaaJrJz",
        "outputId": "618d64be-4ee1-4d69-86ab-c2d40b02f9ee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'Welcome',\n",
              " ',',\n",
              " 'My',\n",
              " 'Name',\n",
              " 'is',\n",
              " 'Olamide',\n",
              " ',',\n",
              " 'and',\n",
              " 'I',\n",
              " 'am',\n",
              " 'learning',\n",
              " \"Naik's\",\n",
              " 'tutorials.',\n",
              " 'I',\n",
              " 'will',\n",
              " 'watch',\n",
              " 'the',\n",
              " 'entire',\n",
              " 'course',\n",
              " '!',\n",
              " 'to',\n",
              " 'become',\n",
              " 'an',\n",
              " 'expert.',\n",
              " 'Thank',\n",
              " 'you',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, RegexpStemmer, SnowballStemmer, WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CepfA_q0LAYV",
        "outputId": "7c8be552-e5ec-4489-a0d0-0a8444bbeea5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WORDs=(\"eating\", \"eats\", \"eaten\", \"writing\", \"writes\", \"programming\", \"programs\", \"history\", \"finally\", \"finalized\")"
      ],
      "metadata": {
        "id": "UKZsZ1tFLYkf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming=PorterStemmer()"
      ],
      "metadata": {
        "id": "f_J8y8U5L2ud"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in WORDs:\n",
        "  print(word+\"---->\"+stemming.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfaFn04oL6Vx",
        "outputId": "4e9494bc-7d13-48fc-9f8a-58fe8d29c067"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---->eat\n",
            "eats---->eat\n",
            "eaten---->eaten\n",
            "writing---->write\n",
            "writes---->write\n",
            "programming---->program\n",
            "programs---->program\n",
            "history---->histori\n",
            "finally---->final\n",
            "finalized---->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$', min=4)"
      ],
      "metadata": {
        "id": "YMMPKG8uNfNk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in WORDs:\n",
        "  print(word+\"---->\"+reg_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKiot5hQN0TT",
        "outputId": "6f022657-8489-45b5-9e83-22c525b3053b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---->eat\n",
            "eats---->eat\n",
            "eaten---->eaten\n",
            "writing---->writ\n",
            "writes---->write\n",
            "programming---->programm\n",
            "programs---->program\n",
            "history---->history\n",
            "finally---->finally\n",
            "finalized---->finalized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snowballstemmer=SnowballStemmer(\"english\")"
      ],
      "metadata": {
        "id": "c3Aaft_uOAWB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in WORDs:\n",
        "  print(word+\"--->\"+snowballstemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI5Gk6poOxnD",
        "outputId": "6a439d6d-aa85-44bf-fda9-a31f7fa117c6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating--->eat\n",
            "eats--->eat\n",
            "eaten--->eaten\n",
            "writing--->write\n",
            "writes--->write\n",
            "programming--->program\n",
            "programs--->program\n",
            "history--->histori\n",
            "finally--->final\n",
            "finalized--->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer=WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "N3L1ZSVzP-rm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in WORDs:\n",
        "  print(word+\"--->\"+lemmatizer.lemmatize(word, pos=\"v\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZbmoX4WSqL5",
        "outputId": "95b2b827-8a15-4bf2-8ebb-6d61ea508eb9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating--->eat\n",
            "eats--->eat\n",
            "eaten--->eat\n",
            "writing--->write\n",
            "writes--->write\n",
            "programming--->program\n",
            "programs--->program\n",
            "history--->history\n",
            "finally--->finally\n",
            "finalized--->finalize\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5APOPlp4_TGS",
        "outputId": "299293fd-4f71-4c74-df09-b82605eb64bd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words(\"english\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK_f_1IrIsNF",
        "outputId": "4aa081cd-1a88-4bc4-e9b6-3a5fd500e69e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\"]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph=\"\"\"\n",
        "In recent years, Nigeria has witnessed an unprecedented surge in technological innovation, particularly in major urban hubs like Lagos, Abuja, and Port Harcourt. What began as a fledgling movement is now a vibrant ecosystem of startups, digital service providers, and a youthful population eager to reshape the country's future.\n",
        "\n",
        "The story of Nigeria’s tech boom is incomplete without mentioning Yaba, a suburb of Lagos often dubbed “Nigeria’s Silicon Valley.” Here, co-working spaces such as the Co-Creation Hub (CcHub) have incubated ideas that blossomed into national and even continental successes. Startups like Paystack, Flutterwave, and PiggyVest have not only revolutionized fintech in Africa but also inspired thousands of young Nigerians to venture into software development, digital marketing, and data science.\n",
        "\n",
        "Beyond the glitz of urban tech success, challenges persist. Unstable electricity supply, inconsistent government policy, and limited access to funding continue to hinder broader growth. However, recent interventions by both local and foreign investors have begun to ease these constraints. Government initiatives like the National Digital Economy Policy are also promising steps in the right direction.\n",
        "\n",
        "Yet, one cannot ignore the role of culture in this transformation. Nigerians are known for their resilience, resourcefulness, and unique sense of hustle—a word that here means much more than just hard work. It encapsulates the creativity and tenacity required to thrive in an environment where obstacles are the norm rather than the exception.\n",
        "\n",
        "Interestingly, this digital renaissance is not limited to Lagos. Cities like Kaduna and Enugu are emerging as new centres for innovation, powered by local talent and a strong sense of community. With improved infrastructure and more inclusive education, these areas could rival the more established tech hubs in the near future.\n",
        "\n",
        "In all, Nigeria stands at a pivotal moment. If the momentum is sustained and the right policies are implemented, the country could very well become the tech capital of Africa. The road ahead is bumpy, but as the popular Nigerian saying goes, “Na small small we go reach there.”\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "q4pTYaAOJA-v"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aqAtuIm5Yxy2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}